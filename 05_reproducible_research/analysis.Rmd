---
title: "Analysis of NOOA data"
subtitle: "How does natural phenomena influence Health and Wealth in the US?"
author: "Matheus Cardoso"
date: "May 28, 2020"
output: 
  html_document: 
    fig_caption: yes
    highlight: zenburn
    keep_md: yes
    theme: simplex
    toc: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, message = FALSE)
```

## Synopsis



## Data Processing

Before even starting to download the data, the environment is configured.

```{r load_libraries}
library(tidyverse)
library(magrittr)
library(data.table)
library(R.utils)
```
To perform this analysis, the data is downloaded from the coursera's [course project](https://www.coursera.org/learn/reproducible-research/peer/OMZ37/course-project-2).
Dataset is saved in `data/storm_data.csv.bz2`, and extracted to `data/storm_data.csv`.
Also, two files that contain explanation about the data are downloaded and save as
`data/storm_data_documentation.pdf` and 
`data/storm_data_faq.pdf`.

```{r download_files}
# set paths and urls
stormdata_url      <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
stormdata_path     <- "data/stormdata.csv.bz2"
stormdata_doc_url  <- "https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf"
stormdata_doc_path <- "data/storm_data_documentation.pdf"
stormdata_faq_url  <- "https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2FNCDC%20Storm%20Events-FAQ%20Page.pdf"
stormdata_faq_path <- "data/storm_data_faq.pdf"

# create ./data folder if it does not exists yet.
if (!dir.exists(dirname(stormdata_path))) {
    dir.create(dirname(stormdata_path))
}

# download data file if it is not yet in disk
if (!file.exists(stormdata_path)) {
    download.file(stormdata_url, stormdata_path, "curl")
}

# download documentation file if it is not yet in disk
if (!file.exists(stormdata_doc_path)) {
    download.file(stormdata_doc_url, stormdata_doc_path, "curl")
}

# download FAQ file if it is not yet in disk
if (!file.exists(stormdata_faq_path)) {
    download.file(stormdata_faq_url, stormdata_faq_path, "curl")
}

# after download, data is extracted
stormdata_file <- "data/stormdata.csv"
if (!file.exists(stormdata_file)) {
   bunzip2(filename = stormdata_path,
           destname = stormdata_file,
           remove   = FALSE) 
}
```

After download, data is loaded into `R` session.
I opted to create a binary file in `.rds` format to avoid parse the raw `.csv` file every time.
This file is located at `data/stormdata.rds`

```{r load_data}
# Load data

## check if the parsed binary exists.
## If doesn't exist, parse raw data
stormdata_parsed <- "data/stormdata.rds"

if(!file.exists(stormdata_parsed)) {
    storm <- read_csv(stormdata_file,
        trim_ws = TRUE,
        col_types = cols_only(
            STATE      = "c",
            EVTYPE     = "c",
            FATALITIES = "d",
            INJURIES   = "d",
            PROPDMG    = "d",
            PROPDMGEXP = "c",
            CROPDMG    = "d",
            CROPDMGEXP = "c"))
    write_rds(storm, stormdata_parsed)
} else {
    storm <- read_rds(stormdata_parsed)
}
```


After load data, the colunms are modified to a more tidy format.
In this dataset, suffix like `K`, `M` and `B` where used to express expoents.
`r 1E3`, `r 1E6` and `r 1E9` respectively.

```{r process_data}
# map `k`, `m` and `b` to powers of ten
storm %<>% mutate(PROPDMGEXP = case_when(str_to_lower(PROPDMGEXP) == "k" ~ 1E3,
                                        str_to_lower(PROPDMGEXP) == "m" ~ 1E6,
                                        str_to_lower(PROPDMGEXP) == "b" ~ 1E9,
                                        str_detect(
                                            str_to_lower(PROPDMGEXP), "^[0-9]$") ~ 10^as.numeric(PROPDMGEXP)))
                                        
storm %<>% mutate(CROPDMGEXP = case_when(str_to_lower(CROPDMGEXP) == "k" ~ 1E3,
                                        str_to_lower(CROPDMGEXP) == "m" ~ 1E6,
                                        str_to_lower(CROPDMGEXP) == "b" ~ 1E9,
                                        str_detect(
                                            str_to_lower(CROPDMGEXP), "^[0-9]$") ~ 10^as.numeric(CROPDMGEXP)))

# transform `PROPDMG` and `CROPDMG` to actual values in dollar
storm %<>%
    mutate(PROPDMG = PROPDMG * PROPDMGEXP,
                 CROPDMG = CROPDMG * CROPDMGEXP) %>% 
    select(-ends_with("EXP"))

# map event types to actual factors
storm %<>% mutate(event = case_when(str_detect(str_to_upper(EVTYPE), "HAIL") ~ "HAIL",
                                     str_detect(str_to_upper(EVTYPE), "WIND") ~ "WIND",
                                     str_detect(str_to_upper(EVTYPE), "TORNADO") ~ "TORNADO",
                                     str_detect(str_to_upper(EVTYPE), "HURRICANE") ~ "HURRICANE",
                                     str_detect(str_to_upper(EVTYPE), "TYPHOON") ~ "TYPHOON",
                                     str_detect(str_to_upper(EVTYPE), "FLOOD") ~ "FLOOD",
                                     str_detect(str_to_upper(EVTYPE), "LIGHTNING") ~ "LIGHTNING",
                                     str_detect(str_to_upper(EVTYPE), "SNOW|BLIZZARD|ICE") ~ "SNOW",
                                     str_detect(str_to_upper(EVTYPE), "STORM|RAIN") ~ "STORM",
                                     str_detect(str_to_upper(EVTYPE), "CLOUD|FOG|SMOKE") ~ "CLOUD",
                                     str_detect(str_to_upper(EVTYPE), "WATERSPOUT") ~ "WATERSPOUT",
                                     str_detect(str_to_upper(EVTYPE), "STREAM") ~ "STREAM",
                                     str_detect(str_to_upper(EVTYPE), "GLAZE") ~ "GLAZE",
                                     str_detect(str_to_upper(EVTYPE), "FUNNEL") ~ "FUNNEL",
                                     str_detect(str_to_upper(EVTYPE), "VOLCAN") ~ "VOLCANO",
                                     str_detect(str_to_upper(EVTYPE), "FIRE") ~ "FIRE",
                                     str_detect(str_to_upper(EVTYPE), "DROUGHT|DUST DEVIL") ~ "DROUGHT",
                                     str_detect(str_to_upper(EVTYPE), "HEAT") ~ "HEAT",
                                     str_detect(str_to_upper(EVTYPE), "COLD|FREEZE") ~ "COLD",
                                     str_detect(str_to_upper(EVTYPE), "WEATHER") ~ "WEATHER")) %>% 
    mutate(EVTYPE = factor(event)) %>% 
    select(-"event")
```

After processing, the dataframe looks like this:

```{r storm_table, include=TRUE, echo=TRUE}
num_of_factors <- storm$EVTYPE %>% unique() %>% length()
set.seed(2)
storm_sample <- storm %>% group_by(EVTYPE) %>% sample_n(1)
knitr::kable(head(storm_sample, n = num_of_factors), booktabs = TRUE)
```

process the data to find common event types

```{r eval=FALSE, include=FALSE}




storm %>% filter(ev == "WIND") 


nm <- storm %>% filter(is.na(ev))
nrow(nm) / nrow(storm) * 100
resu <- storm %>% group_by(ev) %>% summarise(health = sum(FATALITIES, INJURIES, na.rm = T), economy = sum(PROPDMG, CROPDMG, na.rm = T)) %>% arrange(desc(health), desc(economy)) %>% mutate(ev = factor(ev))

ggplot(head(resu)) + geom_point(aes(health, economy, color = ev))

ggplot(head(resu, n = 10)) + geom_bar(aes(ev, weight = health, fill = ev)) + theme(axis.text.x = element_text(angle = 90)) + scale_x_discrete(limits = head(resu$ev, n = 10))

res <- arrange(resu, desc(economy), desc(health))

ggplot(head(res, n = 10)) + geom_bar(aes(ev, weight = economy, fill = ev)) + theme(axis.text.x = element_text(angle = 90)) + scale_x_discrete(limits = head(res$ev, n = 10))

spham <- ham %>% group_by(type) %>% summarise(health = sum(FATALITIES, INJURIES)) %>% arrange(desc(health))

ggplot(spham) + geom_bar(aes(str_to_lower(type), weight = health)) + theme(axis.text.x = element_text(angle = 90)) + scale_x_discrete(limits = spham$type)
```

## Results
